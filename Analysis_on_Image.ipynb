{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. MemN2N_bAbI.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"AM3T017mKvNp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"28LkzM4kKvNw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["np.random.seed(42)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HSJ-WEVjKvNz","colab_type":"text"},"cell_type":"markdown","source":["Download the data"]},{"metadata":{"id":"6ybzStAUKvN1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz --quiet"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zT6IaX57KvN6","colab_type":"text"},"cell_type":"markdown","source":["Parse bAbI stories"]},{"metadata":{"id":"0rpGiJGxKvN7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def parse_stories(lines):\n","    \n","    stories = []\n","    questions = []\n","    answers = []\n","    \n","    story = ''\n","    for line in lines:\n","        line = line.decode('utf-8').strip()\n","        #Get line number and rest of the line\n","        nid, line = line.split(' ', 1)\n","        nid = int(nid)\n","        if nid == 1:\n","            #Start a new story\n","            story = ''\n","        if '\\t' in line:\n","            #End of the story\n","            q, a, supporting = line.split('\\t')\n","            stories.append(story)\n","            questions.append(q)\n","            answers.append(a)            \n","        else:\n","            if (story == ''):\n","                story = line\n","            else:\n","                story += ' ' + line\n","    return stories, questions, answers"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JksNOfyJKvN-","colab_type":"text"},"cell_type":"markdown","source":["Extract the train and test files"]},{"metadata":{"id":"Q4MnM8n1KvN_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import tarfile"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uEeO28WcKvOC","colab_type":"text"},"cell_type":"markdown","source":["Checking the content of the file"]},{"metadata":{"id":"Y583dw4_KvOE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tarfile.open('tasks_1-20_v1-2.tar.gz') as tar:\n","    f = tar.extractfile('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt')\n","    print(f.readlines())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QEw0BVE2KvOM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with tarfile.open('tasks_1-20_v1-2.tar.gz') as tar:\n","    train_stories_txt, train_q_txt, train_a_txt  = parse_stories(tar.extractfile('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train.txt'))\n","    test_stories_txt, test_q_txt, test_a_txt = parse_stories(tar.extractfile('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RzTso2R6KvOQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#tar.getnames()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"auIhDLWfKvOU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_stories_txt[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pdrZelmaDauh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_q_txt[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4Q0EYJRPDeGg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_a_txt[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"me6Uh_TaKvOb","colab_type":"text"},"cell_type":"markdown","source":["# Build Tokenizer"]},{"metadata":{"id":"gfTtHy25KvOd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.preprocessing.text import Tokenizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yhDpwwTPKvOg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["t = Tokenizer()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fmSAJgQ1KvOk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Fit on training data\n","t.fit_on_texts(train_stories_txt)\n","t.fit_on_texts(train_q_txt)\n","t.fit_on_texts(train_a_txt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fVe4TpH9KvOs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Fit on test data\n","t.fit_on_texts(test_stories_txt)\n","t.fit_on_texts(test_q_txt)\n","t.fit_on_texts(test_a_txt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yFKCEmutKvO0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["vocab_size =  len(t.word_index) + 1 #Tokenizer starts with index 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_gQcJzW4KvO3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["vocab_size"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D7pO9tErKvO_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_stories_seq = t.texts_to_sequences(train_stories_txt)\n","train_q_seq = t.texts_to_sequences(train_q_txt)\n","train_a_seq = t.texts_to_sequences(train_a_txt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CUjifp6lKvPC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_stories_seq = t.texts_to_sequences(test_stories_txt)\n","test_q_seq = t.texts_to_sequences(test_q_txt)\n","test_a_seq = t.texts_to_sequences(test_a_txt)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kGi1AuSYKvPI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["story_maxlen = max([len(txt) for txt in train_stories_seq + test_stories_seq])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qYLWxKn3KvPM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["question_maxlen = max([len(txt) for txt in train_q_seq + test_q_seq])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EUvh_mn8KvPS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["answer_maxlen = max([len(txt) for txt in train_a_seq + test_a_seq])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VvfFmfIlKvPX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["story_maxlen"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ac-7AdDyKvPb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["question_maxlen"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rJJFrY-DKvPe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["answer_maxlen"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t8MOmIaIKvPh","colab_type":"text"},"cell_type":"markdown","source":["Pad the sequences"]},{"metadata":{"id":"SBSNiyrqKvPh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.preprocessing.sequence import pad_sequences"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fBfPDOm6KvPj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_stories_seq = pad_sequences(train_stories_seq,maxlen=story_maxlen)\n","train_q_seq = pad_sequences(train_q_seq,maxlen=question_maxlen)\n","train_a_seq = pad_sequences(train_a_seq,maxlen=answer_maxlen)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vUcBCaFDKvPl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_stories_seq = pad_sequences(test_stories_seq,maxlen=story_maxlen)\n","test_q_seq = pad_sequences(test_q_seq,maxlen=question_maxlen)\n","test_a_seq = pad_sequences(test_a_seq,maxlen=answer_maxlen)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qj1ON1HhKvPo","colab_type":"text"},"cell_type":"markdown","source":["int to word converter"]},{"metadata":{"id":"f25qq4WgKvPo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["int_to_word = dict((i,w) for w, i in t.word_index.items())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GQNVXhnKKvPr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["int_to_word[11]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g_g96GYdKvPz","colab_type":"text"},"cell_type":"markdown","source":["# Define the model layers"]},{"metadata":{"id":"cyabAYgFKvPz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.models import Sequential, Model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p5xOh2gNKvP1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from tensorflow.python.keras.layers import Embedding, Dense, LSTM, Activation, dot, Permute, add, concatenate, Dropout, Input"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BAA07EehKvP3","colab_type":"text"},"cell_type":"markdown","source":["Define input for story and question"]},{"metadata":{"id":"UlvMUk3RKvP4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["story = Input(shape=(story_maxlen,))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"th04PtF_KvP6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["question = Input(shape=(question_maxlen,))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LFjKW9_9KvP8","colab_type":"text"},"cell_type":"markdown","source":["Build 3 encoders to provide 3 Embeddings\n","1. Input Memory - m_encoder\n","2. Controller embedding\n","3. Question embedding"]},{"metadata":{"id":"AT6lHcwWKvP8","colab_type":"text"},"cell_type":"markdown","source":["Embedding A for Input memory"]},{"metadata":{"id":"TT0NrPkPKvP9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["m_encoder = Sequential()\n","m_encoder.add(Embedding(input_dim=vocab_size,output_dim=story_maxlen))\n","m_encoder.add(Dropout(0.3))\n","m_embedded_output = m_encoder(story)\n","#output is batch_size x story_maxlen x story_maxlen (embedding size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f6rcesQlKvP-","colab_type":"text"},"cell_type":"markdown","source":["Embedding C for use with Controller"]},{"metadata":{"id":"5das9VdBKvP_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["c_encoder = Sequential()\n","c_encoder.add(Embedding(input_dim=vocab_size, output_dim=question_maxlen))\n","c_encoder.add(Dropout(0.3))\n","c_embedded_output = c_encoder(story)\n","#output is batch_size x story_maxlen x question_maxlen (embedding size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4lg0FbE9KvQB","colab_type":"text"},"cell_type":"markdown","source":["Embedding B for Question"]},{"metadata":{"id":"ihO-mSyzKvQE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["question_encoder = Sequential()\n","question_encoder.add(Embedding(input_dim=vocab_size, output_dim=story_maxlen, input_length=question_maxlen))\n","question_encoder.add(Dropout(0.3))\n","question_embeddding_output = question_encoder(question)\n","#output is batch_size x question_maxlen x story_maxlen (embedding size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rhqinx5nKvQJ","colab_type":"text"},"cell_type":"markdown","source":["Attention"]},{"metadata":{"id":"T4xjYgaKKvQK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["attention_weights = dot([m_embedded_output, question_embeddding_output], axes=(2, 2))\n","attention_weights = Activation('softmax')(attention_weights)\n","#output is batch_size x story_maxlen x question_maxlen"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N94GOAi7KvQM","colab_type":"text"},"cell_type":"markdown","source":["Calculate Weighted_sum (here we are using Add function)"]},{"metadata":{"id":"Cb6uVM6eKvQM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["weighted_sum = add([attention_weights, c_embedded_output])  \n","#Output batch_size x story_maxlen x question_maxlen\n","\n","permuted_weighted_sum = Permute((2, 1))(weighted_sum)  \n","#Output batch_size x question_maxlen x story_maxlen"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OBEIWRbcKvQS","colab_type":"text"},"cell_type":"markdown","source":["Add both permuted_weighted_sum to Question embedding (for first hop)"]},{"metadata":{"id":"WQiaMcrhKvQS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["output_1 = add([permuted_weighted_sum, question_embeddding_output])\n","#Output batch_size x query_maxlen x story_maxlen"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XmQTVPslKvQV","colab_type":"text"},"cell_type":"markdown","source":["Output using LSTM"]},{"metadata":{"id":"s9QfrkC-KvQV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["answer = LSTM(32)(output_1)\n","#Last hidden state - batch_size x 32"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E6vpslGFKvQg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["answer = Dropout(0.3)(answer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"InM_kB0DKvQj","colab_type":"text"},"cell_type":"markdown","source":["FC Layer to predict answer using SoftMax"]},{"metadata":{"id":"tj-2VBrMKvQl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["answer = Dense(vocab_size)(answer)\n","answer = Activation('softmax')(answer)\n","#Output batch_size x vocab_size"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3bsnM7GlKvQu","colab_type":"text"},"cell_type":"markdown","source":["# Build the model"]},{"metadata":{"id":"Sg36B3AEKvQw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model = Model([story, question], answer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-qCS5l67KvQ0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nnOPS6coKvQ3","colab_type":"text"},"cell_type":"markdown","source":["Train the model"]},{"metadata":{"id":"Ej5DWSWAKvQ4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.fit([train_stories_seq, train_q_seq], train_a_seq,\n","          batch_size=32,\n","          epochs=200,\n","          validation_data=([test_stories_seq, test_q_seq], test_a_seq))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zhqYAJaJKvQ9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.save('models/babi_memn2n_task_1.hd5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XHQs_ohjKvRA","colab_type":"text"},"cell_type":"markdown","source":["# Model Prediction"]},{"metadata":{"id":"-6vgv5h6KvRA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_num = 885"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gxAHYMwHKvRD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Get padded story seuqence\n","story_seq_ex = test_stories_seq[test_num]\n","\n","#Get padded question sequence\n","question_seq_ex = test_q_seq[test_num]\n","\n","#reshape to batch_size 1\n","story_seq_ex = np.reshape(story_seq_ex,(1,len(story_seq_ex)))\n","question_seq_ex = np.reshape(question_seq_ex,(1,len(question_seq_ex)))\n","\n","#Predict\n","result = model.predict([story_seq_ex, question_seq_ex])\n","\n","#Get the index with highest probability\n","result = np.argmax(result)\n","\n","#Convert index to word\n","result = int_to_word[result]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g60qRZxHKvRF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["print ('Story : \\n' + test_stories_txt[test_num])\n","print ('Question : \\n' + test_q_txt[test_num])\n","print ('Answer : \\n' + result)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MiQfBytAPpfR","colab_type":"text"},"cell_type":"markdown","source":["### Models Learned\n","\n","1.   Linear Regression -> y = wX + b\n","2.   Linear Classification -> y= softmax(xW+b) - 92%\n","3.   Dense or Fully Connected Layers network -> 97%\n","4.   CNN -> 99%\n","5.   Word2Vec\n","6.   RNN/LSTM/GRU\n","7.   Char-RNN -> Language Modeling\n","8.   Seq2Seq Model \n","9.   Seq2Seq using Attention\n","10. Memory Networks\n","\n"]},{"metadata":{"id":"X4O9j8lSRxeD","colab_type":"text"},"cell_type":"markdown","source":["### Techniques to improve Model\n","\n","1.   Dropout\n","2.   Batching\n","3.   Number of iterations\n","4.   Learning Rate\n","5.   Number of hidden layers\n","6.   Neurons in each layer\n","7.   Normalize the data\n","8.   Optimizers - SGD, Adam, Adadelta\n","9.   Activation functions - ReLU\n","10. CNN - Filter size, stride, padding, pooling\n","11. RNN - Memory units\n","\n"]}]}