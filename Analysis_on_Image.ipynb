{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. MemN2N_bAbI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AM3T017mKvNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import cv2\n",
        "#import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import data\n",
        "from skimage.feature import blob_dog, blob_log, blob_doh\n",
        "from math import sqrt\n",
        "from skimage.color import rgb2gray\n",
        "import glob\n",
        "from skimage.io import imread\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5EQpMSVYTH05",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while(1):\n",
        "\n",
        "    # Take each frame\n",
        "    _, frame = cap.read()\n",
        "\n",
        "    # Convert BGR to HSV\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # define range of blue color in HSV\n",
        "    lower_blue = np.array([110,50,50])\n",
        "    upper_blue = np.array([130,255,255])\n",
        "\n",
        "    # Threshold the HSV image to get only blue colors\n",
        "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "\n",
        "    # Bitwise-AND mask and original image\n",
        "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
        "\n",
        "    cv2.imshow('frame',frame)\n",
        "    cv2.imshow('mask',mask)\n",
        "    cv2.imshow('res',res)\n",
        "    k = cv2.waitKey(5) & 0xFF\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n09jBFVtEVoq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/codebuild81/Image_Processing/master/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HNKuvVZQEsGS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#read image into matrix.\n",
        "#example_file = glob.glob(r\"C:UsersTavishDesktopwint_sky.gif\")[0]\n",
        "example_file = glob.glob(url+\"murillo.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xcQeAHw_TRaB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#example_file = glob.glob(r\"C:UsersTavishDesktopwint_sky.gif\")[0]\n",
        "im = imread(example_file, as_grey=True)\n",
        "plt.imshow(im, cmap=cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "28LkzM4kKvNw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HSJ-WEVjKvNz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download the data"
      ]
    },
    {
      "metadata": {
        "id": "6ybzStAUKvN1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zT6IaX57KvN6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Parse bAbI stories"
      ]
    },
    {
      "metadata": {
        "id": "0rpGiJGxKvN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_stories(lines):\n",
        "    \n",
        "    stories = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    \n",
        "    story = ''\n",
        "    for line in lines:\n",
        "        line = line.decode('utf-8').strip()\n",
        "        #Get line number and rest of the line\n",
        "        nid, line = line.split(' ', 1)\n",
        "        nid = int(nid)\n",
        "        if nid == 1:\n",
        "            #Start a new story\n",
        "            story = ''\n",
        "        if '\\t' in line:\n",
        "            #End of the story\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            stories.append(story)\n",
        "            questions.append(q)\n",
        "            answers.append(a)            \n",
        "        else:\n",
        "            if (story == ''):\n",
        "                story = line\n",
        "            else:\n",
        "                story += ' ' + line\n",
        "    return stories, questions, answers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JksNOfyJKvN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract the train and test files"
      ]
    },
    {
      "metadata": {
        "id": "Q4MnM8n1KvN_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tarfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uEeO28WcKvOC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking the content of the file"
      ]
    },
    {
      "metadata": {
        "id": "Y583dw4_KvOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tarfile.open('tasks_1-20_v1-2.tar.gz') as tar:\n",
        "    f = tar.extractfile('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt')\n",
        "    print(f.readlines())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QEw0BVE2KvOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tarfile.open('tasks_1-20_v1-2.tar.gz') as tar:\n",
        "    train_stories_txt, train_q_txt, train_a_txt  = parse_stories(tar.extractfile('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train.txt'))\n",
        "    test_stories_txt, test_q_txt, test_a_txt = parse_stories(tar.extractfile('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzTso2R6KvOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tar.getnames()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auIhDLWfKvOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_stories_txt[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdrZelmaDauh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_q_txt[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Q0EYJRPDeGg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_a_txt[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "me6Uh_TaKvOb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build Tokenizer"
      ]
    },
    {
      "metadata": {
        "id": "gfTtHy25KvOd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yhDpwwTPKvOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fmSAJgQ1KvOk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fit on training data\n",
        "t.fit_on_texts(train_stories_txt)\n",
        "t.fit_on_texts(train_q_txt)\n",
        "t.fit_on_texts(train_a_txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fVe4TpH9KvOs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fit on test data\n",
        "t.fit_on_texts(test_stories_txt)\n",
        "t.fit_on_texts(test_q_txt)\n",
        "t.fit_on_texts(test_a_txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yFKCEmutKvO0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size =  len(t.word_index) + 1 #Tokenizer starts with index 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_gQcJzW4KvO3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7pO9tErKvO_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_stories_seq = t.texts_to_sequences(train_stories_txt)\n",
        "train_q_seq = t.texts_to_sequences(train_q_txt)\n",
        "train_a_seq = t.texts_to_sequences(train_a_txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUjifp6lKvPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_stories_seq = t.texts_to_sequences(test_stories_txt)\n",
        "test_q_seq = t.texts_to_sequences(test_q_txt)\n",
        "test_a_seq = t.texts_to_sequences(test_a_txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGi1AuSYKvPI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "story_maxlen = max([len(txt) for txt in train_stories_seq + test_stories_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYLWxKn3KvPM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question_maxlen = max([len(txt) for txt in train_q_seq + test_q_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUvh_mn8KvPS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer_maxlen = max([len(txt) for txt in train_a_seq + test_a_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvfFmfIlKvPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "story_maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ac-7AdDyKvPb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question_maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rJJFrY-DKvPe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer_maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8MOmIaIKvPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pad the sequences"
      ]
    },
    {
      "metadata": {
        "id": "SBSNiyrqKvPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fBfPDOm6KvPj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_stories_seq = pad_sequences(train_stories_seq,maxlen=story_maxlen)\n",
        "train_q_seq = pad_sequences(train_q_seq,maxlen=question_maxlen)\n",
        "train_a_seq = pad_sequences(train_a_seq,maxlen=answer_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUcBCaFDKvPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_stories_seq = pad_sequences(test_stories_seq,maxlen=story_maxlen)\n",
        "test_q_seq = pad_sequences(test_q_seq,maxlen=question_maxlen)\n",
        "test_a_seq = pad_sequences(test_a_seq,maxlen=answer_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qj1ON1HhKvPo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "int to word converter"
      ]
    },
    {
      "metadata": {
        "id": "f25qq4WgKvPo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_word = dict((i,w) for w, i in t.word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQNVXhnKKvPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_word[11]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_g96GYdKvPz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define the model layers"
      ]
    },
    {
      "metadata": {
        "id": "cyabAYgFKvPz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Sequential, Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5xOh2gNKvP1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.layers import Embedding, Dense, LSTM, Activation, dot, Permute, add, concatenate, Dropout, Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BAA07EehKvP3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define input for story and question"
      ]
    },
    {
      "metadata": {
        "id": "UlvMUk3RKvP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "story = Input(shape=(story_maxlen,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "th04PtF_KvP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question = Input(shape=(question_maxlen,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFjKW9_9KvP8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build 3 encoders to provide 3 Embeddings\n",
        "1. Input Memory - m_encoder\n",
        "2. Controller embedding\n",
        "3. Question embedding"
      ]
    },
    {
      "metadata": {
        "id": "AT6lHcwWKvP8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Embedding A for Input memory"
      ]
    },
    {
      "metadata": {
        "id": "TT0NrPkPKvP9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m_encoder = Sequential()\n",
        "m_encoder.add(Embedding(input_dim=vocab_size,output_dim=story_maxlen))\n",
        "m_encoder.add(Dropout(0.3))\n",
        "m_embedded_output = m_encoder(story)\n",
        "#output is batch_size x story_maxlen x story_maxlen (embedding size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f6rcesQlKvP-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Embedding C for use with Controller"
      ]
    },
    {
      "metadata": {
        "id": "5das9VdBKvP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_encoder = Sequential()\n",
        "c_encoder.add(Embedding(input_dim=vocab_size, output_dim=question_maxlen))\n",
        "c_encoder.add(Dropout(0.3))\n",
        "c_embedded_output = c_encoder(story)\n",
        "#output is batch_size x story_maxlen x question_maxlen (embedding size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lg0FbE9KvQB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Embedding B for Question"
      ]
    },
    {
      "metadata": {
        "id": "ihO-mSyzKvQE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=story_maxlen, input_length=question_maxlen))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "question_embeddding_output = question_encoder(question)\n",
        "#output is batch_size x question_maxlen x story_maxlen (embedding size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rhqinx5nKvQJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Attention"
      ]
    },
    {
      "metadata": {
        "id": "T4xjYgaKKvQK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "attention_weights = dot([m_embedded_output, question_embeddding_output], axes=(2, 2))\n",
        "attention_weights = Activation('softmax')(attention_weights)\n",
        "#output is batch_size x story_maxlen x question_maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N94GOAi7KvQM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate Weighted_sum (here we are using Add function)"
      ]
    },
    {
      "metadata": {
        "id": "Cb6uVM6eKvQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weighted_sum = add([attention_weights, c_embedded_output])  \n",
        "#Output batch_size x story_maxlen x question_maxlen\n",
        "\n",
        "permuted_weighted_sum = Permute((2, 1))(weighted_sum)  \n",
        "#Output batch_size x question_maxlen x story_maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBEIWRbcKvQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add both permuted_weighted_sum to Question embedding (for first hop)"
      ]
    },
    {
      "metadata": {
        "id": "WQiaMcrhKvQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_1 = add([permuted_weighted_sum, question_embeddding_output])\n",
        "#Output batch_size x query_maxlen x story_maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XmQTVPslKvQV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Output using LSTM"
      ]
    },
    {
      "metadata": {
        "id": "s9QfrkC-KvQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer = LSTM(32)(output_1)\n",
        "#Last hidden state - batch_size x 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6vpslGFKvQg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer = Dropout(0.3)(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "InM_kB0DKvQj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "FC Layer to predict answer using SoftMax"
      ]
    },
    {
      "metadata": {
        "id": "tj-2VBrMKvQl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer = Dense(vocab_size)(answer)\n",
        "answer = Activation('softmax')(answer)\n",
        "#Output batch_size x vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bsnM7GlKvQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build the model"
      ]
    },
    {
      "metadata": {
        "id": "Sg36B3AEKvQw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model([story, question], answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-qCS5l67KvQ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnOPS6coKvQ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ]
    },
    {
      "metadata": {
        "id": "Ej5DWSWAKvQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit([train_stories_seq, train_q_seq], train_a_seq,\n",
        "          batch_size=32,\n",
        "          epochs=200,\n",
        "          validation_data=([test_stories_seq, test_q_seq], test_a_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zhqYAJaJKvQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('models/babi_memn2n_task_1.hd5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XHQs_ohjKvRA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Prediction"
      ]
    },
    {
      "metadata": {
        "id": "-6vgv5h6KvRA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_num = 885"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxAHYMwHKvRD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Get padded story seuqence\n",
        "story_seq_ex = test_stories_seq[test_num]\n",
        "\n",
        "#Get padded question sequence\n",
        "question_seq_ex = test_q_seq[test_num]\n",
        "\n",
        "#reshape to batch_size 1\n",
        "story_seq_ex = np.reshape(story_seq_ex,(1,len(story_seq_ex)))\n",
        "question_seq_ex = np.reshape(question_seq_ex,(1,len(question_seq_ex)))\n",
        "\n",
        "#Predict\n",
        "result = model.predict([story_seq_ex, question_seq_ex])\n",
        "\n",
        "#Get the index with highest probability\n",
        "result = np.argmax(result)\n",
        "\n",
        "#Convert index to word\n",
        "result = int_to_word[result]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g60qRZxHKvRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print ('Story : \\n' + test_stories_txt[test_num])\n",
        "print ('Question : \\n' + test_q_txt[test_num])\n",
        "print ('Answer : \\n' + result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MiQfBytAPpfR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Models Learned\n",
        "\n",
        "1.   Linear Regression -> y = wX + b\n",
        "2.   Linear Classification -> y= softmax(xW+b) - 92%\n",
        "3.   Dense or Fully Connected Layers network -> 97%\n",
        "4.   CNN -> 99%\n",
        "5.   Word2Vec\n",
        "6.   RNN/LSTM/GRU\n",
        "7.   Char-RNN -> Language Modeling\n",
        "8.   Seq2Seq Model \n",
        "9.   Seq2Seq using Attention\n",
        "10. Memory Networks\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "X4O9j8lSRxeD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Techniques to improve Model\n",
        "\n",
        "1.   Dropout\n",
        "2.   Batching\n",
        "3.   Number of iterations\n",
        "4.   Learning Rate\n",
        "5.   Number of hidden layers\n",
        "6.   Neurons in each layer\n",
        "7.   Normalize the data\n",
        "8.   Optimizers - SGD, Adam, Adadelta\n",
        "9.   Activation functions - ReLU\n",
        "10. CNN - Filter size, stride, padding, pooling\n",
        "11. RNN - Memory units\n",
        "\n"
      ]
    }
  ]
}